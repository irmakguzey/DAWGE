defaults:
    # - _self_
    # - agent: cpn # forward model will also be added in the future - TODO: maybe add a wrapper agent class?
    # - encoder: resnet18
    # - trans: mlp
    # - optimizer: adam
    # - agent: pli
    # - optimizer: adam
    # - agent: sbfd
    # - optimizer: adam
    # - trans: mlp
    # - agent: bc
    # - optimizer: adam
    - agent: diffusion
    - optimizer: adam

# TODO: Clean this part I can you can create a custom training config as well
bc_reg_model:
  _target_: contrastive_learning.models.custom_models.BCRegular
  state_dim: ???
  action_dim: ???
  hidden_dim: ???

bc_dist_model:
  _target_: contrastive_learning.models.custom_models.BCDist
  state_dim: ???
  hidden_dim: ???

pli_model:
  _target_: contrastive_learning.models.custom_models.LinearInverse
  input_dim: ??? # They will be set according to the rest of the config
  action_dim: ???
  hidden_dim: ???

pos_encoder: 
  _target_: contrastive_learning.models.custom_models.PosToEmbedding
  input_dim: ???
  hidden_dim: ???
  out_dim: ??? # set it to z_dim

eps_model:
  _target_: contrastive_learning.models.custom_models.EpsModel
  input_dim: ???
  hidden_dim: ???
  output_dim: ???


seed: 42
device: cuda

agent_type: diffusion # cpn / pli / sbfd / bc / diffusion
dataset_type: state # State or visual for now
pos_type: mean_rot # rvec_tvec / corners / mean_rot
pos_ref: global # global / dog / box - which ever it is that will be removed from the other one - sbfd is always global!
train_epochs: 1000
save_frequency: 10 # Frequency to save the model - there will be a test in each step
train_dset_split: 0.8
diff_n_steps: 200

# Hyperparameters to be used everywhere
batch_size: 64
lr: 1e-3
weight_decay: 1e-5
# z_dim: 1000 # resnet18 gives out 1000 dimensions (needed for cpn)
z_dim: 8 # Positions will be mapped to embeddings
pos_dim: 3 # this is needed for state based models - rvec: 3 tvec: 3
hidden_dim: 64 # Expand to 64 first then to z_dim
action_dim: 2

distributed: true
num_workers: 4
world_size: 1
num_gpus: 4

fps: 15 # This should be the same as the all the fps in saving - little differences are not going to be taken
# sec_interval: 0.33 # seconds to separate two timesteps
# frame_interval: 8 # Will be equal to fps * sec_interval - frames to separate two timesteps
frame_interval: 2
video_type: color # NOTE: you could remove this if you want to use both

# this needs to be specified manually
# experiment: ${agent_type}_ref_${pos_ref}_lf_${agent.loss_fn}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}
experiment: ${agent_type}_ref_${pos_ref}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}

data_dir: /home/irmak/Workspace/DAWGE/src/dawge_planner/data/box_orientation_1_demos/train_demos
checkpoint_dir: ??? # Will be set to hydra dir inside the code

# logger
log_frequency: 1

# hydra configuration - should be received separately
hydra:
    run:
        dir: /home/irmak/Workspace/DAWGE/contrastive_learning/out/${now:%Y.%m.%d}/${now:%H-%M}_${experiment}