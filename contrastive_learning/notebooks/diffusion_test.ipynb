{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Test \n",
    "Notebook to test the new diffusion model \n",
    "It should be loading the model, getting random batches from the test dataset and try sampling few next states\n",
    "Both the current and the next state should be plotted with blue and sampled next states should be plotted in green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data \n",
    "\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from contrastive_learning.tests.plotting import plot_corners, plot_rvec_tvec, plot_mean_rot\n",
    "from tqdm import tqdm\n",
    "# \n",
    "from contrastive_learning.tests.test_model import load_lin_model, predict_traj_actions, load_diff_model\n",
    "from contrastive_learning.tests.animate_markers import AnimateMarkers\n",
    "from contrastive_learning.tests.animate_rvec_tvec import AnimateRvecTvec\n",
    "from contrastive_learning.datasets.dataloaders import get_dataloaders\n",
    "\n",
    "from contrastive_learning.models.custom_models import LinearInverse, EpsModel\n",
    "from contrastive_learning.datasets.state_dataset import StateDataset\n",
    "from contrastive_learning.tests.plotting import plot_rvec_tvec, plot_corners\n",
    "from contrastive_learning.datasets.dataloaders import get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "Create the distributed group and load the eps model used for the diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the multiprocessing to load the saved models properly\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29506\"\n",
    "\n",
    "torch.distributed.init_process_group(backend='gloo', rank=0, world_size=1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device and out_dir\n",
    "device = torch.device('cuda:0')\n",
    "out_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/out/2022.08.16/00-48_diffusion_ref_global_fi_5_pt_mean_rot_bs_32_hd_64_lr_0.0001_zd_8'\n",
    "cfg = OmegaConf.load(os.path.join(out_dir, '.hydra/config.yaml'))\n",
    "model_path = os.path.join(out_dir, 'models/eps_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the eps model\n",
    "eps_model = load_diff_model(cfg, device, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_STEPS = cfg.diff_n_steps\n",
    "# N_SAMPLES = 10 # For each state we'll sample 1k different new states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET POS_REF: global\n",
      "self.action_min: [-0.15000001 -0.30000001], self.action_max: [0.15000001 0.30000001]\n"
     ]
    }
   ],
   "source": [
    "_, test_loader, dataset = get_dataloaders(cfg)\n",
    "batch = next(iter(test_loader))\n",
    "x0, xnext0, a = [b.to(device) for b in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionTest:\n",
    "    def __init__(self, eps_model, n_steps, n_samples, device):\n",
    "        self.eps_model = eps_model\n",
    "        self.n_steps = n_steps \n",
    "        self.n_samples = n_samples \n",
    "        self.device = device \n",
    "\n",
    "        self.beta = torch.linspace(0.0001, 0.02, n_steps).to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.n_steps = n_steps # Number of steps to noise and denoise the data\n",
    "        self.sigma2 = self.beta\n",
    "\n",
    "    def gather(self, consts: torch.Tensor, t: torch.Tensor):\n",
    "        c = consts.gather(-1, t)\n",
    "        return c.reshape(-1, 1)\n",
    "\n",
    "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor, x0: torch.Tensor, a: torch.Tensor):\n",
    "        eps_theta = self.eps_model(xt, t, x0, a) # Input to this will be complete noise\n",
    "        alpha_bar = self.gather(self.alpha_bar, t)\n",
    "        alpha = self.gather(self.alpha, t)\n",
    "        eps_coef = (1 - alpha) / (1 - alpha_bar) ** .5\n",
    "        mean = 1 / (alpha ** 0.5) * (xt - eps_coef * eps_theta)\n",
    "        var = self.gather(self.sigma2, t) # (1 - self.alpha)\n",
    "\n",
    "        eps = torch.randn(xt.shape, device=xt.device)\n",
    "        return mean + (var ** 5.) * eps\n",
    "\n",
    "    def get_sample(self, curr_x0, curr_a): # curr_x0.shape: (1, pos_dim*2) - so this is only for one element in the batch\n",
    "        xt = torch.randn((curr_x0.shape), device=curr_x0.device)\n",
    "        for t_ in range(self.n_steps):\n",
    "            curr_t = self.n_steps - t_ - 1\n",
    "            t = xt.new_full((xt.shape[0],), curr_t, dtype=torch.long)\n",
    "            xt = self.p_sample(xt, t, curr_x0, curr_a)\n",
    "        \n",
    "        return xt\n",
    "\n",
    "    def get_all_samples(self, curr_x0, curr_a): # curr_x0.shape: (1, pos_dim*2) - this time the output will be concatenated version of xts\n",
    "        pbar = tqdm(total=self.n_samples)\n",
    "        for i in range(self.n_samples):\n",
    "            if i == 0:\n",
    "                xt = self.get_sample(curr_x0, curr_a)\n",
    "            else:\n",
    "                xt = torch.cat((xt, self.get_sample(curr_x0, curr_a)), dim=0)\n",
    "            pbar.update(1)\n",
    "\n",
    "        pbar.close()\n",
    "        return xt\n",
    "\n",
    "    def get_all_samples_for_batch(self, x0, a):\n",
    "        bs = x0.shape[0]\n",
    "        for i in range(bs):\n",
    "            curr_x0, curr_a = x0[i:i+1], a[i:i+1]\n",
    "            if i == 0:\n",
    "                all_xt = torch.unsqueeze(self.get_all_samples(curr_x0, curr_a),0)\n",
    "            else:\n",
    "                all_xt = torch.cat((all_xt, torch.unsqueeze(self.get_all_samples(curr_x0, curr_a),0)), dim=0)\n",
    "\n",
    "        return all_xt\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 50\n",
    "N_STEPS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 32.26it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.08it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.64it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 49.69it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 45.31it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.48it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.46it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.96it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.76it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.62it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.51it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.41it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 47.29it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.56it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.88it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.51it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.44it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.10it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.18it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 52.25it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.54it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.15it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 46.01it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.74it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.37it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.11it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.96it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.43it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.19it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.58it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 51.11it/s]\n",
      "100%|██████████| 50/50 [00:00<00:00, 50.95it/s]\n"
     ]
    }
   ],
   "source": [
    "diff_test = DiffusionTest(eps_model, n_steps=N_STEPS, n_samples=N_SAMPLES, device=device)\n",
    "all_xt = diff_test.get_all_samples_for_batch(x0, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7478, 0.1294, 0.2482, 0.7092, 0.1449, 0.0974],\n",
      "        [0.7457, 0.1306, 0.2492, 0.7084, 0.1464, 0.1135],\n",
      "        [0.7495, 0.1300, 0.2489, 0.7180, 0.1458, 0.0743],\n",
      "        [0.7443, 0.1313, 0.2501, 0.7077, 0.1476, 0.1211],\n",
      "        [0.7421, 0.1169, 0.2545, 0.6978, 0.1532, 0.4100],\n",
      "        [0.7482, 0.1296, 0.2495, 0.7121, 0.1453, 0.0918],\n",
      "        [0.7421, 0.1086, 0.2525, 0.6783, 0.1419, 0.3889],\n",
      "        [0.7446, 0.1354, 0.2511, 0.7249, 0.1519, 0.1100],\n",
      "        [0.7451, 0.1311, 0.2495, 0.7084, 0.1471, 0.1173],\n",
      "        [0.7543, 0.1261, 0.2483, 0.7175, 0.1429, 0.0482],\n",
      "        [0.7466, 0.1303, 0.2494, 0.7103, 0.1460, 0.1034],\n",
      "        [0.7458, 0.1308, 0.2532, 0.7188, 0.1471, 0.0946],\n",
      "        [0.7435, 0.1160, 0.2488, 0.6878, 0.1497, 0.3892],\n",
      "        [0.7472, 0.1300, 0.2477, 0.7079, 0.1454, 0.1032],\n",
      "        [0.7423, 0.1263, 0.2447, 0.6880, 0.1449, 0.1790],\n",
      "        [0.7467, 0.1300, 0.2489, 0.7085, 0.1458, 0.1046],\n",
      "        [0.7517, 0.1276, 0.2486, 0.7149, 0.1437, 0.0675],\n",
      "        [0.7473, 0.1303, 0.2499, 0.7123, 0.1461, 0.0970],\n",
      "        [0.7443, 0.1306, 0.2493, 0.7045, 0.1468, 0.1272],\n",
      "        [0.7483, 0.1292, 0.2490, 0.7112, 0.1449, 0.0910],\n",
      "        [0.7449, 0.1312, 0.2501, 0.7089, 0.1473, 0.1174],\n",
      "        [0.7447, 0.1312, 0.2499, 0.7080, 0.1474, 0.1212],\n",
      "        [0.7427, 0.1240, 0.2517, 0.6957, 0.1503, 0.2683],\n",
      "        [0.7419, 0.1321, 0.2473, 0.7033, 0.1484, 0.1413],\n",
      "        [0.7421, 0.1250, 0.2533, 0.6981, 0.1513, 0.2599],\n",
      "        [0.7485, 0.1288, 0.2484, 0.7083, 0.1445, 0.0912],\n",
      "        [0.7439, 0.1315, 0.2497, 0.7076, 0.1477, 0.1277],\n",
      "        [0.7548, 0.1263, 0.2486, 0.7207, 0.1431, 0.0455],\n",
      "        [0.7449, 0.1316, 0.2496, 0.7085, 0.1477, 0.1173],\n",
      "        [0.7418, 0.1277, 0.2534, 0.7016, 0.1514, 0.2214],\n",
      "        [0.7444, 0.1315, 0.2497, 0.7087, 0.1476, 0.1222],\n",
      "        [0.7467, 0.1304, 0.2481, 0.7079, 0.1460, 0.1060],\n",
      "        [0.7471, 0.1283, 0.2481, 0.7045, 0.1441, 0.1008],\n",
      "        [0.7447, 0.1307, 0.2495, 0.7065, 0.1467, 0.1219],\n",
      "        [0.7453, 0.1313, 0.2502, 0.7105, 0.1473, 0.1137],\n",
      "        [0.7438, 0.1316, 0.2500, 0.7069, 0.1479, 0.1291],\n",
      "        [0.7446, 0.1323, 0.2495, 0.7106, 0.1482, 0.1173],\n",
      "        [0.7486, 0.1289, 0.2476, 0.7094, 0.1443, 0.0936],\n",
      "        [0.7485, 0.1296, 0.2491, 0.7124, 0.1452, 0.0895],\n",
      "        [0.7457, 0.1315, 0.2498, 0.7110, 0.1473, 0.1114],\n",
      "        [0.7429, 0.1308, 0.2496, 0.7019, 0.1474, 0.1346],\n",
      "        [0.7427, 0.1331, 0.2447, 0.7054, 0.1484, 0.1290],\n",
      "        [0.7432, 0.1317, 0.2502, 0.7070, 0.1481, 0.1350],\n",
      "        [0.7467, 0.1302, 0.2497, 0.7104, 0.1460, 0.1043],\n",
      "        [0.7465, 0.1298, 0.2484, 0.7076, 0.1454, 0.1071],\n",
      "        [0.7216, 0.1213, 0.2763, 0.7402, 0.1748, 0.4679],\n",
      "        [0.7413, 0.0963, 0.2481, 0.6733, 0.1475, 0.7188],\n",
      "        [0.7478, 0.1296, 0.2490, 0.7108, 0.1451, 0.0970],\n",
      "        [0.7405, 0.1304, 0.2537, 0.7035, 0.1520, 0.1901],\n",
      "        [0.7479, 0.1296, 0.2496, 0.7112, 0.1454, 0.0923]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(all_xt[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:05<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the sampled states\n",
    "bs = x0.shape[0]\n",
    "pos_dim = int(x0.shape[1] / 2)\n",
    "if pos_dim == 8: # Pos type is corners\n",
    "    plotting_fn = plot_corners\n",
    "    denormalize_fn = dataset.denormalize_corner\n",
    "elif pos_dim == 6: # Pos type is rotational and translational vectors\n",
    "    plotting_fn = plot_rvec_tvec\n",
    "    denormalize_fn = dataset.denormalize_pos_rvec_tvec # NOTE: This will def cause some problems\n",
    "elif pos_dim == 3: # Pos type is just the mean and rotation of the box\n",
    "    plotting_fn = plot_mean_rot\n",
    "    denormalize_fn = dataset.denormalize_mean_rot\n",
    "\n",
    "ncols = 10\n",
    "nrows = math.ceil(bs / ncols)\n",
    "fig, axs = plt.subplots(figsize=(10*ncols, 10*nrows), nrows=nrows, ncols=ncols)\n",
    "\n",
    "pbar = tqdm(total=bs)\n",
    "# Denormalize all the positions\n",
    "for i in range(bs):\n",
    "    x0_curr = denormalize_fn(x0[i].cpu().detach().numpy())\n",
    "    xnext0_curr = denormalize_fn(xnext0[i].cpu().detach().numpy())\n",
    "\n",
    "    # Plot the denormalized corners\n",
    "    axs_row = int(i / ncols)\n",
    "    axs_col = int(i % ncols)\n",
    "    axs[axs_row, axs_col].set_title(\"Data {} in the batch\".format(i))\n",
    "    _, frame_axis = plotting_fn(axs[axs_row, axs_col], x0_curr, color_scheme=1)\n",
    "    _, frame_axis = plotting_fn(axs[axs_row, axs_col], xnext0_curr, use_frame_axis=True, frame_axis=frame_axis, color_scheme=1)\n",
    "\n",
    "    for j in range(N_SAMPLES):\n",
    "        xt_curr = denormalize_fn(all_xt[i,j].cpu().detach().numpy())\n",
    "        _, frame_axis = plotting_fn(axs[axs_row, axs_col], xt_curr, use_frame_axis=True, frame_axis=frame_axis, color_scheme=2)\n",
    "\n",
    "    pbar.update(1)\n",
    "    \n",
    "# Save the saving plot\n",
    "pbar.close()\n",
    "exp_name = '{}_{}'.format(out_dir.split('/')[-2], out_dir.split('/')[-1].split('_')[0])\n",
    "plt.savefig('diff_samples_{}_steps_{}_samples_{}.png'.format(exp_name, N_STEPS, N_SAMPLES))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dawge')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c54392799b1ea06a5d9c28f64f7b4d3d25501cf92ff871f812783b9868cdd9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
