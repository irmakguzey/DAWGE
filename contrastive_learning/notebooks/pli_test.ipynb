{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data \n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# \n",
    "from contrastive_learning.tests.test_model import load_lin_model, predict_traj_actions\n",
    "from contrastive_learning.tests.animate_markers import AnimateMarkers\n",
    "from contrastive_learning.tests.animate_rvec_tvec import AnimateRvecTvec\n",
    "from contrastive_learning.datasets.dataloaders import get_dataloaders\n",
    "\n",
    "from contrastive_learning.models.custom_models import LinearInverse\n",
    "from contrastive_learning.datasets.state_dataset import StateDataset\n",
    "from contrastive_learning.tests.plotting import plot_rvec_tvec, plot_corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading\n",
    "Create the distributed group\n",
    "Load the linear inverse model from the saved path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the multiprocessing to load the saved models properly\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29504\"\n",
    "\n",
    "torch.distributed.init_process_group(backend='gloo', rank=0, world_size=1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device and out_dir\n",
    "device = torch.device('cuda:0')\n",
    "out_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/out/2022.07.28/10-10_pli_ue_False_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8'\n",
    "cfg = OmegaConf.load(os.path.join(out_dir, '.hydra/config.yaml'))\n",
    "model_path = os.path.join(out_dir, 'models/lin_model.pt')\n",
    "\n",
    "# Load the encoder\n",
    "lin_model = load_lin_model(cfg, device, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistributedDataParallel(\n",
      "  (module): LinearInverse(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=16, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'_target_': 'contrastive_learning.models.agents.pli.PLI', 'loss_fn': 'mse', 'use_encoder': False, 'model': '???', 'optimizer': '???'}, 'optimizer': {'_target_': 'torch.optim.Adam', 'params': '???', 'lr': '???', 'weight_decay': '???'}, 'model': {'_target_': 'contrastive_learning.models.custom_models.LinearInverse', 'input_dim': '???', 'action_dim': '???', 'hidden_dim': '???'}, 'pos_encoder': {'_target_': 'contrastive_learning.models.custom_models.PosToEmbedding', 'input_dim': '???', 'hidden_dim': '???', 'out_dim': '???'}, 'seed': 42, 'device': 'cuda', 'agent_type': 'pli', 'dataset_type': 'state', 'pos_type': 'corners', 'train_epochs': 1000, 'save_frequency': 10, 'train_dset_split': 0.8, 'batch_size': 64, 'lr': 0.001, 'weight_decay': 1e-05, 'z_dim': 8, 'pos_dim': 8, 'hidden_dim': 64, 'action_dim': 2, 'distributed': True, 'num_workers': 4, 'world_size': 1, 'num_gpus': 4, 'fps': 15, 'frame_interval': 1, 'video_type': 'color', 'experiment': '${agent_type}_ue_${agent.use_encoder}_lf_${agent.loss_fn}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}', 'data_dir': '/home/irmak/Workspace/DAWGE/src/dawge_planner/data/move_demos', 'checkpoint_dir': '???', 'log_frequency': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Animation\n",
    "1. Dump every predicted action for given data directory\n",
    "2. Save the predicted and current action in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_name = 'box_marker_move_15'\n",
    "exp_name = '{}_{}'.format(out_dir.split('/')[-2], out_dir.split('/')[-1])\n",
    "data_dir = '/home/irmak/Workspace/DAWGE/src/dawge_planner/data/move_demos/{}'.format(demo_name)\n",
    "dump_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/tests/animations'\n",
    "dump_file = '{}_{}.mp4'.format(demo_name, exp_name)\n",
    "\n",
    "fps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump_file: box_marker_move_15_2022.07.28_10-10_pli_ue_False_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8.mp4\n"
     ]
    }
   ],
   "source": [
    "print('dump_file: {}'.format(dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Action \t Predicted Action\n",
      "[ 0.  -0.3], \t[0.09926589 0.09706353]\n",
      "[ 0.  -0.3], \t[0.09960191 0.09840764]\n",
      "[ 0.  -0.3], \t[0.10094558 0.10378232]\n",
      "[ 0.  -0.3], \t[0.10004813 0.10019249]\n",
      "[ 0.  -0.3], \t[0.09722285 0.08889138]\n",
      "[ 0.  -0.3], \t[0.09646831 0.08587321]\n",
      "[0.15 0.3 ], \t[0.10058965 0.10235861]\n",
      "[0.15 0.3 ], \t[0.10435215 0.11740859]\n",
      "[0.15 0.3 ], \t[0.10636669 0.12546673]\n",
      "[0.15 0.3 ], \t[0.10709914 0.12839656]\n",
      "[0.15 0.3 ], \t[0.1096012  0.13840478]\n",
      "[0.15 0.3 ], \t[0.11459812 0.15839246]\n",
      "[0.15 0.3 ], \t[0.11863635 0.1745454 ]\n",
      "[ 0.  -0.3], \t[0.11931906 0.17727621]\n",
      "[ 0.  -0.3], \t[0.11941175 0.177647  ]\n",
      "[ 0.  -0.3], \t[0.12009514 0.18038057]\n",
      "[0.15 0.3 ], \t[0.1230958 0.1923832]\n",
      "[0.15 0.3 ], \t[0.12269313 0.19077252]\n",
      "[0.15 0.3 ], \t[0.1242359 0.1969436]\n",
      "[0.15 0.3 ], \t[0.11456321 0.15825284]\n",
      "[0.15 0.3 ], \t[0.10570912 0.12283645]\n",
      "[0.15 0.3 ], \t[0.09817298 0.09269193]\n",
      "[0.15 0.3 ], \t[0.09003716 0.06014865]\n",
      "[0.15 0.3 ], \t[0.08321918 0.0328767 ]\n",
      "[ 0.  -0.3], \t[0.07707541 0.00830162]\n",
      "[ 0.  -0.3], \t[ 0.07323178 -0.00707288]\n",
      "[ 0.  -0.3], \t[ 0.07272652 -0.00909394]\n",
      "[ 0.  -0.3], \t[ 0.07311333 -0.0075467 ]\n",
      "[0.15 0.3 ], \t[ 0.07446325 -0.00214702]\n",
      "[0.15 0.3 ], \t[ 0.07332334 -0.00670667]\n",
      "[ 0.  -0.3], \t[ 0.07041586 -0.01833658]\n",
      "[ 0.  -0.3], \t[ 0.06640499 -0.03438006]\n",
      "Actual Action \t Predicted Action\n",
      "[ 0.  -0.3], \t[ 0.06512983 -0.03948069]\n",
      "[ 0.  -0.3], \t[ 0.06467296 -0.04130817]\n",
      "[ 0.  -0.3], \t[ 0.06527311 -0.03890757]\n",
      "[ 0.  -0.3], \t[ 0.06856215 -0.02575142]\n",
      "[ 0.  -0.3], \t[ 0.07240472 -0.01038111]\n",
      "[ 0.  -0.3], \t[0.07602671 0.00410682]\n",
      "[ 0.  -0.3], \t[0.07755587 0.01022347]\n",
      "[0.15 0.3 ], \t[0.08088042 0.02352165]\n",
      "[0.15 0.3 ], \t[0.08380469 0.03521873]\n",
      "[0.15 0.3 ], \t[0.0870892 0.0483568]\n",
      "[0.15 0.3 ], \t[0.09269625 0.070785  ]\n",
      "[0.15 0.3 ], \t[0.09772554 0.09090214]\n",
      "[0.15 0.3 ], \t[0.10217005 0.10868018]\n",
      "[ 0.  -0.3], \t[0.10487445 0.11949778]\n",
      "[0.15 0.3 ], \t[0.10917598 0.1367039 ]\n",
      "[0.15 0.3 ], \t[0.10898349 0.13593396]\n",
      "[0.15 0.3 ], \t[0.11036309 0.14145234]\n",
      "[0.15 0.3 ], \t[0.1099624 0.1398496]\n",
      "[0.15 0.3 ], \t[0.1094633  0.13785317]\n",
      "[0.15 0.3 ], \t[0.11040748 0.1416299 ]\n",
      "[0.15 0.3 ], \t[0.11080841 0.14323361]\n",
      "[0.15 0.3 ], \t[0.11212534 0.14850137]\n",
      "[ 0.  -0.3], \t[0.11415486 0.15661941]\n",
      "[ 0.  -0.3], \t[0.11706793 0.16827172]\n",
      "[ 0.  -0.3], \t[0.11913203 0.17652809]\n",
      "[ 0.  -0.3], \t[0.11960027 0.17840106]\n",
      "[ 0.  -0.3], \t[0.12151013 0.18604053]\n",
      "[ 0.  -0.3], \t[0.12160487 0.18641947]\n",
      "[ 0.  -0.3], \t[0.1219902  0.18796078]\n",
      "[ 0.  -0.3], \t[0.12191366 0.18765461]\n",
      "[ 0.  -0.3], \t[0.12171122 0.18684487]\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "dataset = StateDataset(cfg, single_dir=True, single_dir_root=data_dir)\n",
    "predicted_actions = np.zeros((len(dataset), 2))\n",
    "test_loader = data.DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    curr_pos, next_pos, action = [b.to(device) for b in batch]\n",
    "    pred_action = lin_model(curr_pos, next_pos)\n",
    "\n",
    "    print('Actual Action \\t Predicted Action')\n",
    "    for j in range(len(action)):\n",
    "        print('{}, \\t{}'.format(np.around(dataset.denormalize_action(action[j][0].cpu().detach().numpy()), 2),\n",
    "                                          dataset.denormalize_action(pred_action[j][0].cpu().detach().numpy())))\n",
    "        predicted_actions[i*cfg.batch_size+j,:] = dataset.denormalize_action(pred_action[j][0].cpu().detach().numpy())\n",
    "\n",
    "with open(os.path.join(data_dir, 'predicted_actions.npy'), 'wb') as f:\n",
    "    np.save(f, predicted_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Animation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 63/63 [00:09<00:00,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animation saved to: /home/irmak/Workspace/DAWGE/contrastive_learning/tests/animations/box_marker_move_15_2022.07.28_10-10_pli_ue_False_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if cfg.pos_type == 'corners':\n",
    "    AnimateMarkers(\n",
    "        data_dir = data_dir, \n",
    "        dump_dir = dump_dir, \n",
    "        dump_file = dump_file, \n",
    "        fps = fps,\n",
    "        mult_traj = False,\n",
    "        show_predicted_action = True \n",
    "    ) # Saves them in the given dump_file\n",
    "elif cfg.pos_type == 'rvec_tvec':\n",
    "    AnimateRvecTvec(\n",
    "        data_dir = data_dir, \n",
    "        dump_dir = dump_dir, \n",
    "        dump_file = dump_file,\n",
    "        fps = fps,\n",
    "        show_predicted_action=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Prediction Image\n",
    "Predict the action for each frame in the test dataset and dump them in a grid image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.batch_size = 32\n",
    "train_loader, test_loader, dataset = get_dataloaders(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)\n",
    "batch = next(iter(test_loader))\n",
    "curr_pos, next_pos, action = [b.to(device) for b in batch]\n",
    "pred_action = lin_model(curr_pos, next_pos)\n",
    "\n",
    "curr_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3576, 0.2308, 0.3382, 0.2531, 0.3155, 0.2350, 0.3366, 0.2140, 0.2905,\n",
      "        0.2713, 0.3091, 0.2951, 0.2832, 0.3133, 0.2646, 0.2881],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(curr_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n"
     ]
    }
   ],
   "source": [
    "nrows = 4\n",
    "ncols = int(cfg.batch_size / nrows)\n",
    "fig, axs = plt.subplots(figsize=(ncols*10,nrows*10), nrows=nrows, ncols=ncols) # Draw the predicted action\n",
    "print(axs.shape)\n",
    "\n",
    "for i in range(cfg.batch_size):\n",
    "    axs_row = int(i / nrows)\n",
    "    axs_col = int(i % nrows)\n",
    "    \n",
    "    action_np = dataset.denormalize_action(action[i].cpu().detach().numpy())\n",
    "    pred_action_np = dataset.denormalize_action(pred_action[i].cpu().detach().numpy())\n",
    "    \n",
    "    if cfg.pos_type == 'corners':\n",
    "        curr_pos_np = dataset.denormalize_corner(curr_pos[i].cpu().detach().numpy())\n",
    "        plot_corners(\n",
    "            ax=axs[axs_col, axs_row],\n",
    "            curr_pos=curr_pos_np,\n",
    "            use_img=False,\n",
    "            img=None,\n",
    "            plot_action=True,\n",
    "            actions=(action_np, pred_action_np))\n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        curr_pos_np = dataset.denormalize_pos_rvec_tvec(curr_pos[i].cpu().detach().numpy())\n",
    "        plot_rvec_tvec(\n",
    "            ax=axs[axs_col, axs_row],\n",
    "            curr_pos=curr_pos_np,\n",
    "            use_img=False,\n",
    "            img=None,\n",
    "            plot_action=True,\n",
    "            actions=(action_np, pred_action_np))\n",
    "        \n",
    "plt.savefig(os.path.join(out_dir, 'pil_action_test.jpg'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c54392799b1ea06a5d9c28f64f7b4d3d25501cf92ff871f812783b9868cdd9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
