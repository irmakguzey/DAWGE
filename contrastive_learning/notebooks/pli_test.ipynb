{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data \n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# \n",
    "from contrastive_learning.tests.test_model import load_lin_model, predict_traj_actions\n",
    "from contrastive_learning.tests.animate_markers import AnimateMarkers\n",
    "from contrastive_learning.tests.animate_rvec_tvec import AnimateRvecTvec\n",
    "from contrastive_learning.datasets.dataloaders import get_dataloaders\n",
    "\n",
    "from contrastive_learning.models.custom_models import LinearInverse\n",
    "from contrastive_learning.datasets.state_dataset import StateDataset\n",
    "from contrastive_learning.tests.plotting import plot_rvec_tvec, plot_corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading\n",
    "Create the distributed group\n",
    "Load the linear inverse model from the saved path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the multiprocessing to load the saved models properly\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29504\"\n",
    "\n",
    "torch.distributed.init_process_group(backend='gloo', rank=0, world_size=1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device and out_dir\n",
    "device = torch.device('cuda:0')\n",
    "out_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/out/2022.07.29/16-37_pli_ref_dog_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8'\n",
    "cfg = OmegaConf.load(os.path.join(out_dir, '.hydra/config.yaml'))\n",
    "if not ('pos_ref' in cfg):\n",
    "    cfg.pos_ref = 'global'\n",
    "model_path = os.path.join(out_dir, 'models/lin_model.pt')\n",
    "\n",
    "# Load the encoder\n",
    "lin_model = load_lin_model(cfg, device, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistributedDataParallel(\n",
      "  (module): LinearInverse(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=16, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'_target_': 'contrastive_learning.models.agents.pli.PLI', 'loss_fn': 'mse', 'use_encoder': False, 'model': '???', 'optimizer': '???'}, 'optimizer': {'_target_': 'torch.optim.Adam', 'params': '???', 'lr': '???', 'weight_decay': '???'}, 'model': {'_target_': 'contrastive_learning.models.custom_models.LinearInverse', 'input_dim': '???', 'action_dim': '???', 'hidden_dim': '???'}, 'pos_encoder': {'_target_': 'contrastive_learning.models.custom_models.PosToEmbedding', 'input_dim': '???', 'hidden_dim': '???', 'out_dim': '???'}, 'seed': 42, 'device': 'cuda', 'agent_type': 'pli', 'dataset_type': 'state', 'pos_type': 'corners', 'pos_ref': 'dog', 'train_epochs': 1000, 'save_frequency': 10, 'train_dset_split': 0.8, 'batch_size': 64, 'lr': 0.001, 'weight_decay': 1e-05, 'z_dim': 8, 'pos_dim': 8, 'hidden_dim': 64, 'action_dim': 2, 'distributed': True, 'num_workers': 4, 'world_size': 1, 'num_gpus': 4, 'fps': 15, 'frame_interval': 1, 'video_type': 'color', 'experiment': '${agent_type}_ref_${pos_ref}_lf_${agent.loss_fn}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}', 'data_dir': '/home/irmak/Workspace/DAWGE/src/dawge_planner/data/train_demos', 'checkpoint_dir': '???', 'log_frequency': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Animation\n",
    "1. Dump every predicted action for given data directory\n",
    "2. Save the predicted and current action in a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_name = 'box_marker_test_2'\n",
    "exp_name = '{}_{}'.format(out_dir.split('/')[-2], out_dir.split('/')[-1])\n",
    "data_dir = '/home/irmak/Workspace/DAWGE/src/dawge_planner/data/test_demos/{}'.format(demo_name)\n",
    "dump_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/tests/animations'\n",
    "dump_file = '{}_{}.mp4'.format(demo_name, exp_name)\n",
    "\n",
    "fps = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump_file: box_marker_test_2_2022.07.29_16-37_pli_ref_dog_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8.mp4\n"
     ]
    }
   ],
   "source": [
    "print('dump_file: {}'.format(dump_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET POS_REF: dog\n",
      "len(dataset): 56\n",
      "self.action_min: [ 0.         -0.30000001], self.action_max: [0.15000001 0.        ]\n",
      "Actual Action \t Predicted Action\n",
      "[0.15 0.  ], \t[0.15877299 0.01754597]\n",
      "[0.15 0.  ], \t[0.15687031 0.0137406 ]\n",
      "[0.15 0.  ], \t[0.15570372 0.01140744]\n",
      "[0.15 0.  ], \t[0.15716417 0.01432833]\n",
      "[0.15 0.  ], \t[0.15796438 0.01592875]\n",
      "[0.15 0.  ], \t[ 0.1485647  -0.00287061]\n",
      "[0.15 0.  ], \t[0.15189894 0.00379787]\n",
      "[0.15 0.  ], \t[0.15620145 0.01240289]\n",
      "[ 0.  -0.3], \t[ 0.10847038 -0.08305925]\n",
      "[ 0.  -0.3], \t[ 0.01745292 -0.26509416]\n",
      "[0.15 0.  ], \t[ 0.10777617 -0.08444767]\n",
      "[0.15 0.  ], \t[0.15333682 0.00667362]\n",
      "[0.15 0.  ], \t[0.15993788 0.01987574]\n",
      "[0.15 0.  ], \t[0.1575466  0.01509318]\n",
      "[0.15 0.  ], \t[0.15239663 0.00479325]\n",
      "[ 0.  -0.3], \t[ 0.07883311 -0.14233379]\n",
      "[ 0.  -0.3], \t[ 0.04349591 -0.21300819]\n",
      "[ 0.  -0.3], \t[ 0.04921746 -0.2015651 ]\n",
      "[0.15 0.  ], \t[ 0.12727907 -0.04544188]\n",
      "[0.15 0.  ], \t[ 0.13148425 -0.03703151]\n",
      "[0.15 0.  ], \t[ 0.13394012 -0.03211978]\n",
      "[0.15 0.  ], \t[ 0.13603535 -0.02792931]\n",
      "[0.15 0.  ], \t[ 0.13175331 -0.03649339]\n",
      "[0.15 0.  ], \t[ 0.09790605 -0.10418791]\n",
      "[ 0.  -0.3], \t[ 0.09685661 -0.10628679]\n",
      "[0.15 0.  ], \t[ 0.12412169 -0.05175662]\n",
      "[0.15 0.  ], \t[ 0.1336187  -0.03276261]\n",
      "[0.15 0.  ], \t[ 0.1375989  -0.02480221]\n",
      "[0.15 0.  ], \t[ 0.13218871 -0.0356226 ]\n",
      "[0.15 0.  ], \t[ 0.13035545 -0.03928911]\n",
      "[0.15 0.  ], \t[ 0.13274891 -0.03450219]\n",
      "[0.15 0.  ], \t[ 0.13464293 -0.03071416]\n",
      "[ 0.  -0.3], \t[ 0.07128315 -0.15743371]\n",
      "[0.15 0.  ], \t[ 0.13986363 -0.02027274]\n",
      "[0.15 0.  ], \t[ 0.13710645 -0.02578712]\n",
      "[0.15 0.  ], \t[ 0.13169268 -0.03661466]\n",
      "[0.15 0.  ], \t[ 0.1388935  -0.02221302]\n",
      "[0.15 0.  ], \t[ 0.14290192 -0.01419618]\n",
      "[ 0.  -0.3], \t[ 0.05421818 -0.19156366]\n",
      "[0.15 0.  ], \t[ 0.12596393 -0.04807216]\n",
      "[0.15 0.  ], \t[ 0.1285232  -0.04295361]\n",
      "[0.15 0.  ], \t[ 0.13274675 -0.03450651]\n",
      "[0.15 0.  ], \t[ 0.13079206 -0.03841589]\n",
      "[0.15 0.  ], \t[ 0.13405721 -0.0318856 ]\n",
      "[0.15 0.  ], \t[ 0.13380923 -0.03238156]\n",
      "[ 0.  -0.3], \t[ 0.09247615 -0.11504771]\n",
      "[0.15 0.  ], \t[ 0.10333705 -0.09332591]\n",
      "[0.15 0.  ], \t[ 0.12506809 -0.04986384]\n",
      "[0.15 0.  ], \t[ 0.12633575 -0.04732851]\n",
      "[0.15 0.  ], \t[ 0.13114368 -0.03771265]\n",
      "[0.15 0.  ], \t[ 0.13265214 -0.03469573]\n",
      "[0.15 0.  ], \t[ 0.14474931 -0.01050139]\n",
      "[0.15 0.  ], \t[ 0.12539319 -0.04921364]\n",
      "[0.15 0.  ], \t[ 0.11859129 -0.06281743]\n",
      "[0.15 0.  ], \t[ 0.11791522 -0.06416956]\n",
      "[0.15 0.  ], \t[ 0.09797413 -0.10405176]\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset\n",
    "dataset = StateDataset(cfg, single_dir=True, single_dir_root=data_dir)\n",
    "predicted_actions = np.zeros((len(dataset), 2))\n",
    "test_loader = data.DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    curr_pos, next_pos, action = [b.to(device) for b in batch]\n",
    "    pred_action = lin_model(curr_pos, next_pos)\n",
    "\n",
    "    print('Actual Action \\t Predicted Action')\n",
    "    for j in range(len(action)):\n",
    "        print('{}, \\t{}'.format(np.around(dataset.denormalize_action(action[j][0].cpu().detach().numpy()), 2),\n",
    "                                          dataset.denormalize_action(pred_action[j][0].cpu().detach().numpy())))\n",
    "        predicted_actions[i*cfg.batch_size+j,:] = dataset.denormalize_action(pred_action[j][0].cpu().detach().numpy())\n",
    "\n",
    "with open(os.path.join(data_dir, 'predicted_actions.npy'), 'wb') as f:\n",
    "    np.save(f, predicted_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Animation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:08<00:00,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animation saved to: /home/irmak/Workspace/DAWGE/contrastive_learning/tests/animations/box_marker_test_2_2022.07.29_16-37_pli_ref_dog_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.001_zd_8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if cfg.pos_type == 'corners':\n",
    "    AnimateMarkers(\n",
    "        data_dir = data_dir, \n",
    "        dump_dir = dump_dir, \n",
    "        dump_file = dump_file, \n",
    "        fps = fps,\n",
    "        mult_traj = False,\n",
    "        show_predicted_action = True \n",
    "    ) # Saves them in the given dump_file\n",
    "elif cfg.pos_type == 'rvec_tvec':\n",
    "    AnimateRvecTvec(\n",
    "        data_dir = data_dir, \n",
    "        dump_dir = dump_dir, \n",
    "        dump_file = dump_file,\n",
    "        fps = fps,\n",
    "        show_predicted_action=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Prediction Image\n",
    "Predict the action for each frame in the test dataset and dump them in a grid image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET POS_REF: global\n",
      "len(dataset): 4910\n",
      "self.action_min: [-0.15000001 -0.30000001], self.action_max: [0.15000001 0.30000001]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "cfg.batch_size = 32\n",
    "global_cfg = deepcopy(cfg)\n",
    "global_cfg.pos_ref = 'global'\n",
    "train_loader, test_loader, dataset = get_dataloaders(global_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_pos: tensor([[0.2031, 0.4182, 0.2160, 0.3832, 0.2492, 0.3888, 0.2371, 0.4252, 0.1820,\n",
      "         0.4811, 0.2144, 0.4951, 0.1950, 0.5329, 0.1602, 0.5175],\n",
      "        [0.3584, 0.3175, 0.3786, 0.2951, 0.4021, 0.3147, 0.3819, 0.3399, 0.3139,\n",
      "         0.3538, 0.3422, 0.3678, 0.3269, 0.3972, 0.2969, 0.3818],\n",
      "        [0.4175, 0.0979, 0.3981, 0.1105, 0.3835, 0.0923, 0.4029, 0.0811, 0.3588,\n",
      "         0.1189, 0.3714, 0.1378, 0.3487, 0.1462, 0.3370, 0.1266],\n",
      "        [0.3341, 0.1469, 0.3414, 0.1692, 0.3139, 0.1790, 0.3074, 0.1552, 0.3851,\n",
      "         0.1608, 0.3770, 0.1399, 0.4005, 0.1301, 0.4086, 0.1483],\n",
      "        [0.5728, 0.2783, 0.5485, 0.2909, 0.5340, 0.2643, 0.5583, 0.2531, 0.5057,\n",
      "         0.3077, 0.4984, 0.3385, 0.4693, 0.3245, 0.4773, 0.2951],\n",
      "        [0.2225, 0.1622, 0.1966, 0.1566, 0.2095, 0.1343, 0.2354, 0.1399, 0.2540,\n",
      "         0.1846, 0.2662, 0.1622, 0.2905, 0.1664, 0.2799, 0.1888],\n",
      "        [0.3018, 0.3469, 0.2937, 0.3818, 0.2597, 0.3748, 0.2694, 0.3413, 0.2896,\n",
      "         0.4629, 0.3252, 0.4559, 0.3285, 0.4909, 0.2921, 0.4993],\n",
      "        [0.3568, 0.3748, 0.3479, 0.4126, 0.3155, 0.4042, 0.3252, 0.3678, 0.3641,\n",
      "         0.3510, 0.3341, 0.3441, 0.3430, 0.3091, 0.3722, 0.3161],\n",
      "        [0.3058, 0.7650, 0.2686, 0.7413, 0.2929, 0.6881, 0.3293, 0.7091, 0.3414,\n",
      "         0.8350, 0.3641, 0.7762, 0.4013, 0.7972, 0.3794, 0.8587],\n",
      "        [0.3083, 0.1874, 0.2985, 0.2126, 0.2710, 0.2056, 0.2816, 0.1804, 0.2589,\n",
      "         0.2490, 0.2832, 0.2643, 0.2646, 0.2867, 0.2403, 0.2699],\n",
      "        [0.3786, 0.1958, 0.3600, 0.2154, 0.3382, 0.1986, 0.3568, 0.1804, 0.3123,\n",
      "         0.2280, 0.3309, 0.2462, 0.3066, 0.2615, 0.2888, 0.2434],\n",
      "        [0.1610, 0.2769, 0.1837, 0.2937, 0.1594, 0.3203, 0.1359, 0.3035, 0.2217,\n",
      "         0.2587, 0.2015, 0.2448, 0.2209, 0.2196, 0.2419, 0.2336],\n",
      "        [0.2338, 0.3860, 0.2403, 0.4210, 0.2047, 0.4350, 0.1990, 0.3986, 0.2031,\n",
      "         0.4951, 0.2379, 0.5063, 0.2217, 0.5455, 0.1853, 0.5329],\n",
      "        [0.0922, 0.2643, 0.1100, 0.2825, 0.0833, 0.3077, 0.0639, 0.2895, 0.1820,\n",
      "         0.3063, 0.1659, 0.2853, 0.1909, 0.2601, 0.2079, 0.2811],\n",
      "        [0.4992, 0.2210, 0.4725, 0.2280, 0.4644, 0.2028, 0.4903, 0.1972, 0.4320,\n",
      "         0.2154, 0.4401, 0.2406, 0.4126, 0.2448, 0.4061, 0.2196],\n",
      "        [0.3641, 0.2182, 0.3892, 0.2056, 0.4029, 0.2280, 0.3778, 0.2406, 0.3358,\n",
      "         0.2476, 0.3503, 0.2713, 0.3228, 0.2839, 0.3091, 0.2587],\n",
      "        [0.4134, 0.2434, 0.4191, 0.2168, 0.4466, 0.2238, 0.4409, 0.2490, 0.3369,\n",
      "         0.2249, 0.3636, 0.2310, 0.3573, 0.2543, 0.3293, 0.2481],\n",
      "        [0.5356, 0.1399, 0.5372, 0.1636, 0.5121, 0.1608, 0.5121, 0.1385, 0.5668,\n",
      "         0.1475, 0.5776, 0.1319, 0.5973, 0.1397, 0.5878, 0.1554],\n",
      "        [0.3592, 0.8014, 0.3196, 0.7790, 0.3422, 0.7217, 0.3794, 0.7427, 0.3964,\n",
      "         0.8713, 0.4167, 0.8098, 0.4555, 0.8322, 0.4361, 0.8951],\n",
      "        [0.3180, 0.1902, 0.3447, 0.1832, 0.3528, 0.2084, 0.3244, 0.2168, 0.3608,\n",
      "         0.1594, 0.3430, 0.1455, 0.3608, 0.1273, 0.3786, 0.1399],\n",
      "        [0.3964, 0.3189, 0.3827, 0.2937, 0.4102, 0.2797, 0.4231, 0.3049, 0.4320,\n",
      "         0.3650, 0.4628, 0.3720, 0.4571, 0.4014, 0.4256, 0.3930],\n",
      "        [0.2338, 0.3636, 0.2209, 0.4000, 0.1885, 0.3916, 0.2023, 0.3566, 0.1691,\n",
      "         0.4476, 0.2006, 0.4573, 0.1828, 0.4951, 0.1497, 0.4839],\n",
      "        [0.2136, 0.4727, 0.2184, 0.5147, 0.1788, 0.5287, 0.1756, 0.4867, 0.1254,\n",
      "         0.7231, 0.1683, 0.7245, 0.1545, 0.7846, 0.1100, 0.7818],\n",
      "        [0.4377, 0.2587, 0.4393, 0.2322, 0.4676, 0.2336, 0.4660, 0.2615, 0.3576,\n",
      "         0.2168, 0.3827, 0.2294, 0.3697, 0.2503, 0.3447, 0.2378],\n",
      "        [0.3503, 0.3021, 0.3746, 0.3217, 0.3536, 0.3483, 0.3293, 0.3259, 0.4013,\n",
      "         0.3608, 0.4231, 0.3399, 0.4450, 0.3594, 0.4231, 0.3818],\n",
      "        [0.1529, 0.4979, 0.1602, 0.4573, 0.1966, 0.4531, 0.1917, 0.4951, 0.1294,\n",
      "         0.5720, 0.1634, 0.5874, 0.1400, 0.6336, 0.1052, 0.6154],\n",
      "        [0.4887, 0.1762, 0.5121, 0.1678, 0.5243, 0.1902, 0.5000, 0.1986, 0.4612,\n",
      "         0.1986, 0.4717, 0.2238, 0.4466, 0.2294, 0.4361, 0.2042],\n",
      "        [0.2727, 0.2140, 0.3026, 0.2112, 0.3066, 0.2378, 0.2759, 0.2420, 0.2379,\n",
      "         0.2224, 0.2354, 0.2490, 0.2047, 0.2490, 0.2079, 0.2210],\n",
      "        [0.1626, 0.3636, 0.1966, 0.3483, 0.2047, 0.3804, 0.1699, 0.3986, 0.2613,\n",
      "         0.3483, 0.2330, 0.3385, 0.2500, 0.3049, 0.2775, 0.3147],\n",
      "        [0.1982, 0.3469, 0.2063, 0.3147, 0.2387, 0.3161, 0.2314, 0.3483, 0.1893,\n",
      "         0.4056, 0.2233, 0.4042, 0.2160, 0.4406, 0.1804, 0.4392],\n",
      "        [0.1917, 0.5860, 0.2290, 0.6014, 0.2071, 0.6531, 0.1699, 0.6350, 0.1440,\n",
      "         0.6112, 0.1214, 0.6629, 0.0850, 0.6448, 0.1092, 0.5916],\n",
      "        [0.1650, 0.4462, 0.1723, 0.4070, 0.2071, 0.4056, 0.2015, 0.4434, 0.1278,\n",
      "         0.5119, 0.1626, 0.5189, 0.1464, 0.5608, 0.1100, 0.5524]],\n",
      "       device='cuda:0'), next_pos: tensor([[0.2184, 0.3958, 0.2346, 0.3622, 0.2662, 0.3720, 0.2516, 0.4056, 0.1982,\n",
      "         0.4545, 0.2314, 0.4671, 0.2120, 0.5035, 0.1788, 0.4895],\n",
      "        [0.3584, 0.3189, 0.3786, 0.2951, 0.4021, 0.3147, 0.3827, 0.3399, 0.3220,\n",
      "         0.3552, 0.3479, 0.3748, 0.3277, 0.4014, 0.3010, 0.3818],\n",
      "        [0.4361, 0.0951, 0.4175, 0.1077, 0.4021, 0.0909, 0.4207, 0.0797, 0.3738,\n",
      "         0.1147, 0.3851, 0.1343, 0.3617, 0.1413, 0.3519, 0.1203],\n",
      "        [0.3147, 0.1483, 0.3228, 0.1706, 0.2953, 0.1818, 0.2888, 0.1580, 0.3673,\n",
      "         0.1622, 0.3592, 0.1427, 0.3835, 0.1315, 0.3916, 0.1510],\n",
      "        [0.5841, 0.2783, 0.5615, 0.2937, 0.5445, 0.2685, 0.5655, 0.2545, 0.5235,\n",
      "         0.3231, 0.5170, 0.3538, 0.4879, 0.3399, 0.4951, 0.3119],\n",
      "        [0.2079, 0.1629, 0.1828, 0.1566, 0.1966, 0.1343, 0.2217, 0.1406, 0.2391,\n",
      "         0.1860, 0.2516, 0.1629, 0.2759, 0.1671, 0.2646, 0.1902],\n",
      "        [0.3010, 0.3455, 0.2937, 0.3818, 0.2605, 0.3762, 0.2686, 0.3427, 0.2751,\n",
      "         0.4727, 0.3107, 0.4573, 0.3204, 0.4909, 0.2848, 0.5077],\n",
      "        [0.3406, 0.3916, 0.3350, 0.4294, 0.3010, 0.4266, 0.3074, 0.3874, 0.3495,\n",
      "         0.3636, 0.3212, 0.3510, 0.3350, 0.3189, 0.3633, 0.3301],\n",
      "        [0.2824, 0.7385, 0.2468, 0.7161, 0.2710, 0.6629, 0.3066, 0.6853, 0.3180,\n",
      "         0.8056, 0.3439, 0.7510, 0.3786, 0.7762, 0.3536, 0.8336],\n",
      "        [0.3212, 0.1734, 0.3139, 0.1972, 0.2864, 0.1916, 0.2953, 0.1678, 0.2751,\n",
      "         0.2350, 0.3002, 0.2503, 0.2824, 0.2713, 0.2573, 0.2545],\n",
      "        [0.3900, 0.1930, 0.3706, 0.2112, 0.3503, 0.1944, 0.3689, 0.1762, 0.3228,\n",
      "         0.2238, 0.3358, 0.2462, 0.3091, 0.2573, 0.2969, 0.2350],\n",
      "        [0.1529, 0.2965, 0.1772, 0.3147, 0.1537, 0.3427, 0.1286, 0.3231, 0.2176,\n",
      "         0.2699, 0.1926, 0.2601, 0.2087, 0.2308, 0.2338, 0.2406],\n",
      "        [0.2371, 0.3748, 0.2411, 0.4098, 0.2055, 0.4210, 0.2023, 0.3846, 0.1982,\n",
      "         0.4839, 0.2346, 0.4881, 0.2249, 0.5287, 0.1869, 0.5245],\n",
      "        [0.0833, 0.2797, 0.0922, 0.3049, 0.0583, 0.3231, 0.0502, 0.2965, 0.1642,\n",
      "         0.3385, 0.1481, 0.3175, 0.1731, 0.2909, 0.1901, 0.3119],\n",
      "        [0.5194, 0.2224, 0.4935, 0.2294, 0.4846, 0.2042, 0.5089, 0.1972, 0.4523,\n",
      "         0.2168, 0.4608, 0.2420, 0.4337, 0.2462, 0.4264, 0.2203],\n",
      "        [0.3794, 0.2084, 0.4037, 0.1972, 0.4175, 0.2182, 0.3940, 0.2322, 0.3519,\n",
      "         0.2378, 0.3657, 0.2615, 0.3398, 0.2741, 0.3261, 0.2476],\n",
      "        [0.4288, 0.2490, 0.4337, 0.2224, 0.4612, 0.2280, 0.4571, 0.2545, 0.3487,\n",
      "         0.2140, 0.3746, 0.2224, 0.3665, 0.2448, 0.3390, 0.2364],\n",
      "        [0.5364, 0.1413, 0.5380, 0.1636, 0.5121, 0.1622, 0.5121, 0.1385, 0.5594,\n",
      "         0.1491, 0.5681, 0.1325, 0.5888, 0.1387, 0.5813, 0.1550],\n",
      "        [0.3350, 0.7846, 0.2977, 0.7608, 0.3220, 0.7049, 0.3584, 0.7287, 0.3722,\n",
      "         0.8545, 0.3932, 0.7944, 0.4312, 0.8168, 0.4110, 0.8797],\n",
      "        [0.3220, 0.1902, 0.3487, 0.1860, 0.3544, 0.2112, 0.3261, 0.2168, 0.3665,\n",
      "         0.1608, 0.3455, 0.1497, 0.3608, 0.1273, 0.3811, 0.1399],\n",
      "        [0.3997, 0.3147, 0.3843, 0.2895, 0.4110, 0.2741, 0.4264, 0.2979, 0.4506,\n",
      "         0.3552, 0.4814, 0.3636, 0.4741, 0.3916, 0.4442, 0.3818],\n",
      "        [0.2411, 0.3483, 0.2273, 0.3832, 0.1958, 0.3748, 0.2104, 0.3413, 0.1756,\n",
      "         0.4280, 0.2071, 0.4392, 0.1893, 0.4741, 0.1561, 0.4629],\n",
      "        [0.2136, 0.4727, 0.2184, 0.5147, 0.1788, 0.5287, 0.1756, 0.4867, 0.1294,\n",
      "         0.7245, 0.1691, 0.7357, 0.1481, 0.7944, 0.1068, 0.7818],\n",
      "        [0.4434, 0.2657, 0.4409, 0.2392, 0.4693, 0.2378, 0.4717, 0.2643, 0.3633,\n",
      "         0.2210, 0.3851, 0.2378, 0.3689, 0.2573, 0.3455, 0.2406],\n",
      "        [0.3511, 0.3021, 0.3746, 0.3217, 0.3536, 0.3483, 0.3301, 0.3273, 0.3948,\n",
      "         0.3720, 0.4142, 0.3469, 0.4385, 0.3622, 0.4199, 0.3888],\n",
      "        [0.1691, 0.4741, 0.1780, 0.4322, 0.2136, 0.4322, 0.2063, 0.4713, 0.1464,\n",
      "         0.5427, 0.1804, 0.5580, 0.1578, 0.6000, 0.1230, 0.5832],\n",
      "        [0.5049, 0.1734, 0.5267, 0.1650, 0.5396, 0.1874, 0.5162, 0.1958, 0.4773,\n",
      "         0.1958, 0.4887, 0.2196, 0.4644, 0.2266, 0.4539, 0.2014],\n",
      "        [0.2848, 0.2154, 0.3139, 0.2140, 0.3147, 0.2420, 0.2848, 0.2434, 0.2532,\n",
      "         0.2224, 0.2508, 0.2490, 0.2209, 0.2490, 0.2233, 0.2210],\n",
      "        [0.1456, 0.3902, 0.1804, 0.3720, 0.1909, 0.4042, 0.1553, 0.4252, 0.2451,\n",
      "         0.3734, 0.2176, 0.3608, 0.2354, 0.3273, 0.2629, 0.3385],\n",
      "        [0.1998, 0.3231, 0.2071, 0.2923, 0.2387, 0.2923, 0.2314, 0.3231, 0.1909,\n",
      "         0.3790, 0.2241, 0.3804, 0.2160, 0.4140, 0.1812, 0.4126],\n",
      "        [0.2071, 0.5944, 0.2468, 0.6000, 0.2346, 0.6531, 0.1934, 0.6476, 0.1594,\n",
      "         0.6294, 0.1448, 0.6853, 0.1036, 0.6755, 0.1189, 0.6210],\n",
      "        [0.1715, 0.4280, 0.1812, 0.3930, 0.2152, 0.3958, 0.2071, 0.4322, 0.1335,\n",
      "         0.4923, 0.1683, 0.4979, 0.1521, 0.5385, 0.1165, 0.5315]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)\n",
    "batch = next(iter(test_loader))\n",
    "curr_pos, next_pos, action = [b.to(device) for b in batch]\n",
    "print('curr_pos: {}, next_pos: {}'.format(curr_pos, next_pos))\n",
    "\n",
    "# Normalize the current and next pos before inputting to the linear model\n",
    "ref_tensor = torch.zeros((curr_pos.shape))\n",
    "half_idx = int(curr_pos.shape[1] / 2) # In order not to have a control for pos_type\n",
    "if cfg.pos_ref == 'dog':\n",
    "    ref_tensor = curr_pos[:,half_idx:]\n",
    "    ref_tensor = ref_tensor.repeat(1,2)\n",
    "elif cfg.pos_ref == 'box':\n",
    "    ref_tensor = curr_pos[:,:half_idx]\n",
    "    ref_tensor = ref_tensor.repeat(1,2)\n",
    "\n",
    "# curr_pos += ref_tensor\n",
    "# print('curr_pos: {}'.format(curr_pos))\n",
    "\n",
    "\n",
    "pred_action = lin_model(curr_pos-ref_tensor, next_pos-ref_tensor)\n",
    "\n",
    "curr_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2031, 0.4182, 0.2160, 0.3832, 0.2492, 0.3888, 0.2371, 0.4252, 0.1820,\n",
      "        0.4811, 0.2144, 0.4951, 0.1950, 0.5329, 0.1602, 0.5175],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(curr_pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8)\n"
     ]
    }
   ],
   "source": [
    "nrows = 4\n",
    "ncols = int(cfg.batch_size / nrows)\n",
    "fig, axs = plt.subplots(figsize=(ncols*10,nrows*10), nrows=nrows, ncols=ncols) # Draw the predicted action\n",
    "print(axs.shape)\n",
    "\n",
    "for i in range(cfg.batch_size):\n",
    "    axs_row = int(i / nrows)\n",
    "    axs_col = int(i % nrows)\n",
    "    \n",
    "    action_np = dataset.denormalize_action(action[i].cpu().detach().numpy())\n",
    "    pred_action_np = dataset.denormalize_action(pred_action[i].cpu().detach().numpy())\n",
    "    \n",
    "    if cfg.pos_type == 'corners':\n",
    "        curr_pos_np = dataset.denormalize_corner(curr_pos[i].cpu().detach().numpy())\n",
    "        plot_corners(\n",
    "            ax=axs[axs_col, axs_row],\n",
    "            curr_pos=curr_pos_np,\n",
    "            use_img=False,\n",
    "            img=None,\n",
    "            plot_action=True,\n",
    "            actions=(action_np, pred_action_np))\n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        curr_pos_np = dataset.denormalize_pos_rvec_tvec(curr_pos[i].cpu().detach().numpy())\n",
    "        plot_rvec_tvec(\n",
    "            ax=axs[axs_col, axs_row],\n",
    "            curr_pos=curr_pos_np,\n",
    "            use_img=False,\n",
    "            img=None,\n",
    "            plot_action=True,\n",
    "            actions=(action_np, pred_action_np))\n",
    "        \n",
    "plt.savefig(os.path.join(out_dir, 'pil_action_test.jpg'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n"
     ]
    }
   ],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c54392799b1ea06a5d9c28f64f7b4d3d25501cf92ff871f812783b9868cdd9b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
