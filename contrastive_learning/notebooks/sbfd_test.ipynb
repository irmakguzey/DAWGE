{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb5f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data \n",
    "\n",
    "from cv2 import aruco\n",
    "from omegaconf import OmegaConf\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# Custom imports\n",
    "from contrastive_learning.datasets.state_dataset import StateDataset\n",
    "from contrastive_learning.tests.test_model import load_sbfd, save_all_embeddings, get_closest_embeddings\n",
    "from contrastive_learning.tests.plotting import plot_corners, plot_rvec_tvec\n",
    "from contrastive_learning.datasets.dataloaders import get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea9e1f9",
   "metadata": {},
   "source": [
    "### Model Loading\n",
    "Load the trans and the position encoder that will be used in testing the positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60930de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the multiprocessing to load the saved models properly\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29504\"\n",
    "\n",
    "torch.distributed.init_process_group(backend='gloo', rank=0, world_size=1)\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5ebe165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device and out_dir\n",
    "device = torch.device('cuda:0')\n",
    "out_dir = '/home/irmak/Workspace/DAWGE/contrastive_learning/out/2022.08.03/13-49_sbfd_ref_global_lf_mse_fi_1_pt_corners_bs_64_hd_64_lr_0.0001_zd_8'\n",
    "cfg = OmegaConf.load(os.path.join(out_dir, '.hydra/config.yaml'))\n",
    "if cfg.agent.use_encoder == False:\n",
    "    cfg.z_dim = cfg.pos_dim*2\n",
    "pos_encoder_path = os.path.join(out_dir, 'models/pos_encoder.pt')\n",
    "trans_path = os.path.join(out_dir, 'models/trans.pt')\n",
    "fps = 15\n",
    "\n",
    "# Load the position encoder and forward linear model\n",
    "pos_encoder, trans = load_sbfd(cfg, device, pos_encoder_path, trans_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a485d325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_encoder: DistributedDataParallel(\n",
      "  (module): PosToEmbedding(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "), trans: DistributedDataParallel(\n",
      "  (module): Transition(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=20, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('pos_encoder: {}, trans: {}'.format(pos_encoder, trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e091c9f",
   "metadata": {},
   "source": [
    "### Dump all the embeddings / positions\n",
    "Dump or get all the embeddings index by index to the `out_dir`. \n",
    "These embeddings will be used to get the closest kth positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c92b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predicted_pos(cfg, data_loader, trans):\n",
    "    all_pred_pos = np.zeros((len(data_loader.dataset), cfg.pos_dim*2))\n",
    "    for i,batch in enumerate(data_loader):\n",
    "        _, next_pos, action = [b.to(device) for b in batch]\n",
    "#         pred_pos = trans(curr_pos, action)\n",
    "        all_pred_pos[i*cfg.batch_size:(i+1)*cfg.batch_size, :] = next_pos.cpu().detach().numpy()\n",
    "        \n",
    "    return all_pred_pos\n",
    "\n",
    "def get_closest_pos(all_pos, curr_pos, k):\n",
    "    curr_pos = curr_pos.cpu().detach().numpy()\n",
    "    dist = np.linalg.norm(all_pos - curr_pos, axis=1)\n",
    "    closest_pos_idx = np.argsort(dist)[:k]\n",
    "    \n",
    "    return closest_pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b6f5e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET POS_REF: global\n",
      "len(dataset): 6356\n",
      "self.action_min: [-0.15000001 -0.30000001], self.action_max: [0.15000001 0.30000001]\n"
     ]
    }
   ],
   "source": [
    "# Create a whole dataset and dump all the embeddings to the out_dir\n",
    "data_dir = '/home/irmak/Workspace/DAWGE/src/dawge_planner/data'\n",
    "dataset = StateDataset(cfg)\n",
    "data_loader = data.DataLoader(dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n",
    "if cfg.agent.use_encoder:\n",
    "    # Use same method that is used on resnet18 cpn testing\n",
    "    # We are basically doing the same thing - all and all next embeddings in the dataset is saved in out_dir with this\n",
    "    save_all_embeddings(device, len(dataset), cfg.z_dim, pos_encoder, data_loader, out_dir) \n",
    "else:\n",
    "    all_pos = get_all_predicted_pos(cfg, data_loader, trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad255f",
   "metadata": {},
   "source": [
    "### Predict next embeddings for the test dataset\n",
    "1. Load the `test_loader` using `get_dataloaders` \n",
    "2. Predict the next embeddings using `trans` and `pos_encoder`.\n",
    "3. Find the closest embeddings to the predicted next embeddings. (And their index).\n",
    "4. Get the indexed item from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df92e061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET POS_REF: global\n",
      "len(dataset): 6356\n",
      "self.action_min: [-0.15000001 -0.30000001], self.action_max: [0.15000001 0.30000001]\n"
     ]
    }
   ],
   "source": [
    "cfg.batch_size = 16\n",
    "_, test_loader, _ = get_dataloaders(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a08084f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272\n"
     ]
    }
   ],
   "source": [
    "print(len(test_loader.dataset))\n",
    "batch = next(iter(test_loader))\n",
    "curr_pos, next_pos, action = [b.to(device) for b in batch]\n",
    "if cfg.agent.use_encoder:\n",
    "    z, z_next = pos_encoder(curr_pos), pos_encoder(next_pos)\n",
    "    z_delta = trans(z, action)\n",
    "    z_next_predict = z + z_delta\n",
    "    print('z.shape: {}, z_next.shape: {}, z_next_predict.shape: {}'.format(\n",
    "        z.shape, z_next.shape, z_next_predict.shape\n",
    "    ))\n",
    "else:\n",
    "    pos_delta = trans(curr_pos, action)\n",
    "    pos_next_predict = curr_pos + pos_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a94e4daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "print(curr_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ca8d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA_INTRINSICS = np.array([[612.82019043,   0.        , 322.14050293],\n",
    "                              [  0.        , 611.48303223, 247.9083252 ],\n",
    "                              [  0.        ,   0.        ,   1.        ]])\n",
    "\n",
    "# def plot_rvec_tvec(ax, curr_pos, use_img=False, img=None): # Color scheme is to have an alternative color for polygon colors\n",
    "#     if use_img == False:\n",
    "#         img_shape = (720, 1280, 3)\n",
    "#         blank_image = np.ones(img_shape, np.uint8) * 255\n",
    "#         img = ax.imshow(blank_image.copy())\n",
    "\n",
    "#     for j in range(2):\n",
    "#         curr_rvec_tvec = curr_pos[j*6:(j+1)*6]\n",
    "#         if j == 0:\n",
    "#             frame_axis = aruco.drawAxis(img.get_array().copy(),\n",
    "#                 CAMERA_INTRINSICS,\n",
    "#                 np.zeros((5)),\n",
    "#                 curr_rvec_tvec[:3], curr_rvec_tvec[3:],\n",
    "#                 0.01)\n",
    "#         else:\n",
    "#             frame_axis = aruco.drawAxis(frame_axis.copy(),\n",
    "#                 CAMERA_INTRINSICS,\n",
    "#                 np.zeros((5)),\n",
    "#                 curr_rvec_tvec[:3], curr_rvec_tvec[3:],\n",
    "#                 0.01)\n",
    "\n",
    "#     img.set_array(frame_axis) # If use_img is true then img will not be none\n",
    "#     ax.plot()\n",
    "\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d684651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the current and next positions \n",
    "k = 1 # k stands for the kth nearest neighbour\n",
    "nrows = cfg.batch_size\n",
    "ncols = k+2 # kth nearest neighbours and current and next position\n",
    "fig, axs = plt.subplots(figsize=(ncols*10,nrows*10), nrows=nrows, ncols=ncols)\n",
    "# cfg.pos_type = 'rvec_tvec' # or corners\n",
    "\n",
    "for i in range(cfg.batch_size):\n",
    "    \n",
    "    action_np = dataset.denormalize_action(action[i].cpu().detach().numpy())\n",
    "    if cfg.pos_type == 'corners':\n",
    "        curr_pos_np = dataset.denormalize_corner(curr_pos[i].cpu().detach().numpy())\n",
    "        next_pos_np = dataset.denormalize_corner(next_pos[i].cpu().detach().numpy())\n",
    "        pred_pos_np = dataset.denormalize_corner(pos_next_predict[i].cpu().detach().numpy())\n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        curr_pos_np = dataset.denormalize_pos_rvec_tvec(curr_pos[i].cpu().detach().numpy())\n",
    "        next_pos_np = dataset.denormalize_pos_rvec_tvec(next_pos[i].cpu().detach().numpy())\n",
    "        pred_pos_np = dataset.denormalize_pos_rvec_tvec(pos_next_predict[i].cpu().detach().numpy())\n",
    "    \n",
    "    # Plot the current position\n",
    "    axs[i,0].set_title(\"Actual Current Positions\")\n",
    "    if cfg.pos_type == 'corners':\n",
    "        _, frame_axis = plot_corners(axs[i,0], curr_pos_np, plot_action=True, actions=[action_np], color_scheme=1)\n",
    "        plot_corners(axs[i,0], next_pos_np, plot_action=False, use_frame_axis=True, frame_axis=frame_axis, color_scheme=2)\n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        img = plot_rvec_tvec(axs[i,0], curr_pos_np)\n",
    "        plot_rvec_tvec(axs[i,0], next_pos_np, use_img=True, img=img)\n",
    "#         _, frame_axis = plot_rvec_tvec(axs[i,0], curr_pos_np, plot_action=True, actions=[action_np])\n",
    "#         plot_rvec_tvec(axs[i,0], next_pos_np, plot_action=False, use_frame_axis=True, frame_axis=frame_axis)\n",
    "    \n",
    "    # Plot the next state\n",
    "    axs[i,1].set_title(\"Next Positions\")\n",
    "    if cfg.pos_type == 'corners':\n",
    "        plot_corners(axs[i,1], next_pos_np, plot_action=False, color_scheme=1)\n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        plot_rvec_tvec(axs[i,1], next_pos_np)\n",
    "        \n",
    "    axs[i,2].set_title(\"Predicted Next Position\")\n",
    "    if cfg.pos_type == 'corners':\n",
    "        _, frame_axis = plot_corners(axs[i,2], next_pos_np, plot_action=False, color_scheme=1)\n",
    "        plot_corners(axs[i,2], pred_pos_np, use_frame_axis=True, frame_axis=frame_axis, plot_action=False, color_scheme=2)\n",
    "        \n",
    "    elif cfg.pos_type == 'rvec_tvec':\n",
    "        img = plot_rvec_tvec(axs[i,2], next_pos_np) # TODO: Change these and remove the plotting method above\n",
    "        plot_rvec_tvec(axs[i,2], pred_pos_np, use_img=True, img=img) \n",
    "        \n",
    "plt.savefig(os.path.join(out_dir, 'sbfd_test.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46363887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162730cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
